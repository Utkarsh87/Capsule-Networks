{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsNetTest2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1VB8cTZgiHqcUV56Q2qo9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utkarsh87/Capsule-Networks/blob/master/src/CapsNetTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LItUXlV-jq5O"
      },
      "source": [
        "!unzip CapsNet.zip && mv CapsNet/* ."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrIxYF6lkj5f",
        "outputId": "d3afb51d-3ffe-4d0a-9415-faa5aae8bd58"
      },
      "source": [
        "!python main.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9913344it [05:01, 32885.97it/s]\n",
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "29696it [00:00, 338157.02it/s]\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1649664it [00:51, 32191.69it/s]                 \n",
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "5120it [00:00, 14559211.17it/s]\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "Processing...\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "============================== Architecture ==============================\n",
            "CapsuleNetwork(\n",
            "  (conv_layer): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1))\n",
            "  (primary_capsule): PrimaryCaps(\n",
            "    (capsules): ModuleList(\n",
            "      (0): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (1): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (2): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (3): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (4): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (5): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (6): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "      (7): Conv2d(256, 32, kernel_size=(9, 9), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (digit_capsule): DigitCaps()\n",
            "  (decoder): DeconvDecoder(\n",
            "    (deconv): Sequential(\n",
            "      (0): Linear(in_features=160, out_features=784, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): CustomReshape()\n",
            "      (3): BatchNorm2d(16, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
            "      (4): ConvTranspose2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (6): CustomPad()\n",
            "      (7): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      (8): CustomPad()\n",
            "      (9): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (10): Flatten(start_dim=1, end_dim=-1)\n",
            "      (11): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "==========================================================================\n",
            "\n",
            "Sizes of parameters: \n",
            "conv_layer.weight: [256, 1, 9, 9]\n",
            "conv_layer.bias: [256]\n",
            "primary_capsule.capsules.0.weight: [32, 256, 9, 9]\n",
            "primary_capsule.capsules.0.bias: [32]\n",
            "primary_capsule.capsules.1.weight: [32, 256, 9, 9]\n",
            "primary_capsule.capsules.1.bias: [32]\n",
            "primary_capsule.capsules.2.weight: [32, 256, 9, 9]\n",
            "primary_capsule.capsules.2.bias: [32]\n",
            "primary_capsule.capsules.3.weight: [32, 256, 9, 9]\n",
            "primary_capsule.capsules.3.bias: [32]\n",
            "primary_capsule.capsules.4.weight: [32, 256, 9, 9]\n",
            "primary_capsule.capsules.4.bias: [32]\n",
            "primary_capsule.capsules.5.weight: [32, 256, 9, 9]\n",
            "primary_capsule.capsules.5.bias: [32]\n",
            "primary_capsule.capsules.6.weight: [32, 256, 9, 9]\n",
            "primary_capsule.capsules.6.bias: [32]\n",
            "primary_capsule.capsules.7.weight: [32, 256, 9, 9]\n",
            "primary_capsule.capsules.7.bias: [32]\n",
            "digit_capsule.W: [10, 1152, 8, 16]\n",
            "decoder.deconv.0.weight: [784, 160]\n",
            "decoder.deconv.0.bias: [784]\n",
            "decoder.deconv.3.weight: [16]\n",
            "decoder.deconv.3.bias: [16]\n",
            "decoder.deconv.4.weight: [16, 64, 3, 3]\n",
            "decoder.deconv.4.bias: [64]\n",
            "decoder.deconv.5.weight: [64, 32, 3, 3]\n",
            "decoder.deconv.5.bias: [32]\n",
            "decoder.deconv.7.weight: [32, 16, 3, 3]\n",
            "decoder.deconv.7.bias: [16]\n",
            "decoder.deconv.9.weight: [16, 1, 3, 3]\n",
            "decoder.deconv.9.bias: [1]\n",
            "\n",
            "Total number of parameters: 6974513 \n",
            "\n",
            "Training on GPU\n",
            "Epoch: 1 \tTraining Loss: 0.36082532\n",
            "Epoch: 1 \tTraining Loss: 0.20080591\n",
            "Epoch: 1 \tTraining Loss: 0.15842536\n",
            "Epoch: 1 \tTraining Loss: 0.12880533\n",
            "Epoch: 1 \tTraining Loss: 0.11690944\n",
            "Epoch: 1 \tTraining Loss: 0.10266615\n",
            "Epoch: 2 \tTraining Loss: 0.09024304\n",
            "Epoch: 2 \tTraining Loss: 0.08510357\n",
            "Epoch: 2 \tTraining Loss: 0.08015055\n",
            "Epoch: 2 \tTraining Loss: 0.07921490\n",
            "Epoch: 2 \tTraining Loss: 0.07635330\n",
            "Epoch: 2 \tTraining Loss: 0.07108778\n",
            "Epoch: 3 \tTraining Loss: 0.06115582\n",
            "Epoch: 3 \tTraining Loss: 0.06117415\n",
            "Epoch: 3 \tTraining Loss: 0.06003497\n",
            "Epoch: 3 \tTraining Loss: 0.06241902\n",
            "Epoch: 3 \tTraining Loss: 0.05633817\n",
            "Epoch: 3 \tTraining Loss: 0.05954635\n",
            "Epoch: 4 \tTraining Loss: 0.05381162\n",
            "Epoch: 4 \tTraining Loss: 0.05218232\n",
            "Epoch: 4 \tTraining Loss: 0.05027861\n",
            "Epoch: 4 \tTraining Loss: 0.04798776\n",
            "Epoch: 4 \tTraining Loss: 0.04951741\n",
            "Epoch: 4 \tTraining Loss: 0.05270473\n",
            "Epoch: 5 \tTraining Loss: 0.04800592\n",
            "Epoch: 5 \tTraining Loss: 0.04642344\n",
            "Epoch: 5 \tTraining Loss: 0.04252254\n",
            "Epoch: 5 \tTraining Loss: 0.04370177\n",
            "Epoch: 5 \tTraining Loss: 0.04316028\n",
            "Epoch: 5 \tTraining Loss: 0.04504110\n",
            "Epoch: 6 \tTraining Loss: 0.03918690\n",
            "Epoch: 6 \tTraining Loss: 0.03969458\n",
            "Epoch: 6 \tTraining Loss: 0.04157650\n",
            "Epoch: 6 \tTraining Loss: 0.04219955\n",
            "Epoch: 6 \tTraining Loss: 0.04010404\n",
            "Epoch: 6 \tTraining Loss: 0.04042376\n",
            "Epoch: 7 \tTraining Loss: 0.03852254\n",
            "Epoch: 7 \tTraining Loss: 0.03615642\n",
            "Epoch: 7 \tTraining Loss: 0.03788922\n",
            "Epoch: 7 \tTraining Loss: 0.03507016\n",
            "Epoch: 7 \tTraining Loss: 0.03730240\n",
            "Epoch: 7 \tTraining Loss: 0.03664536\n",
            "Epoch: 8 \tTraining Loss: 0.03467043\n",
            "Epoch: 8 \tTraining Loss: 0.03299225\n",
            "Epoch: 8 \tTraining Loss: 0.03208758\n",
            "Epoch: 8 \tTraining Loss: 0.03394798\n",
            "Epoch: 8 \tTraining Loss: 0.03647750\n",
            "Epoch: 8 \tTraining Loss: 0.03499068\n",
            "Epoch: 9 \tTraining Loss: 0.03058898\n",
            "Epoch: 9 \tTraining Loss: 0.03132364\n",
            "Epoch: 9 \tTraining Loss: 0.03080393\n",
            "Epoch: 9 \tTraining Loss: 0.03296414\n",
            "Epoch: 9 \tTraining Loss: 0.03260709\n",
            "Epoch: 9 \tTraining Loss: 0.03161017\n",
            "Epoch: 10 \tTraining Loss: 0.02875339\n",
            "Epoch: 10 \tTraining Loss: 0.02962973\n",
            "Epoch: 10 \tTraining Loss: 0.02984963\n",
            "Epoch: 10 \tTraining Loss: 0.02884065\n",
            "Epoch: 10 \tTraining Loss: 0.03172343\n",
            "Epoch: 10 \tTraining Loss: 0.03007601\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL0HK71Ygl1u"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}