{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsNet MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqPnMGnyxtLPyMu7OXDLkp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utkarsh87/Capsule-Networks/blob/master/CapsNet_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP02CKQi3cOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N52x_hV93xDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5YKhA3e3xFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cFnWoEwo19P",
        "colab_type": "text"
      },
      "source": [
        "Load in MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCRAEcpU3xH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWtZM9W-o5mb",
        "colab_type": "text"
      },
      "source": [
        "Visualise a few of the MNIST images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq9HcfHD3xKv",
        "colab_type": "code",
        "outputId": "3d604bbd-5fe5-4649-db54-a72d91f7c4b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "n_samples = 5\n",
        "\n",
        "plt.figure(figsize=(n_samples * 2, 3))\n",
        "for index in range(n_samples):\n",
        "    plt.subplot(1, n_samples, index + 1)\n",
        "    sample_image = train_images[index].reshape(28, 28)\n",
        "    plt.imshow(sample_image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnuRYa_JBHHB",
        "colab_type": "text"
      },
      "source": [
        "# Primary Capsules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuV5LqwBqd3H",
        "colab_type": "text"
      },
      "source": [
        "**Define the conv layers of the network.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqBvyMHV3xQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "relu_conv1 = tf.keras.layers.Conv2D(256, (9, 9), strides=(1, 1), input_shape=(None, 28, 28, 1))\n",
        "conv2 = tf.keras.layers.Conv2D(256, (9, 9), strides=(2, 2), input_shape=(None, 20, 20, 256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xshjJWArauE",
        "colab_type": "text"
      },
      "source": [
        "**Pass the images through the conv layers.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ta17a4PTgdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape and rescale\n",
        "train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n",
        "train_images = train_images*1.0/255.0\n",
        "# print(train_images.shape)\n",
        "\n",
        "# batch training needed due to high number of training samples\n",
        "batch_size = 64\n",
        "samples_per_batch = train_images.shape[0]//batch_size\n",
        "\n",
        "num_batches = 2\n",
        "\n",
        "# pass the images through the first 2 conv layers to get a (6, 6, 256) output\n",
        "output2 = np.empty((num_batches, 64, 6, 6, 256))\n",
        "for i in range(num_batches):\n",
        "  x = (relu_conv1(train_images[i*batch_size : (i+1)*batch_size]))\n",
        "  op = (conv2(x))\n",
        "  op_np = op.numpy()\n",
        "  np.append(output2, op_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGsZpcBHT31f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c95f3e01-aaaf-49b6-e0d2-5f1a3dc4ce23"
      },
      "source": [
        "print(output2.shape)\n",
        "output2 = output2.reshape((num_batches*batch_size, 6, 6, 8, 32))\n",
        "output2 = output2.reshape((num_batches*batch_size, 1152, 8))\n",
        "output2.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 64, 6, 6, 256)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 1152, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzhNmdW45svz",
        "colab_type": "text"
      },
      "source": [
        "**Now we need to squash the vectors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e0uzyD2yi-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First convert the np array to a tensor\n",
        "out2 = tf.convert_to_tensor(output2, dtype=tf.float32)\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "# Squash function implementation taken from XifengGuo\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIFg6nZy7H9O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f99a86fa-19d6-425c-e244-3fecbcbc6c88"
      },
      "source": [
        "caps1_output = squash(out2)\n",
        "# print(caps1_output.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 1152, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vch-l-LQAVOE",
        "colab_type": "text"
      },
      "source": [
        "Now we have the outputs from the Primary capsule layer(child layer) ready, to comoute the output of the next capule layer, i.e., the DigiCaps layer(parent layer), we need to get the predicted output vectors(one for each child/parent capsule pair). After having the predicted output vectors ready we can run the routing-by-agreement algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcFZJGJJA9MS",
        "colab_type": "text"
      },
      "source": [
        "# Digit Capsules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naN-PpY1Bify",
        "colab_type": "text"
      },
      "source": [
        "**Compute the predicted output vectors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3f_RtyqCGTZ",
        "colab_type": "text"
      },
      "source": [
        "The DigiCaps layer will contain 10 capsules(one for each digit), each a 16-dimensional vector. Hence the transformation matrix Wij has a shape (16, 8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYBm1y8qHk2D",
        "colab_type": "text"
      },
      "source": [
        "To get the predicted vectors, need to multiply the output of the primary capsule layers with the transformation matrices. The output of this matmul will be how the output of a capsule in the child layer relates spatially with the capsule in the parent layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrZukW6f7z7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a0d05ff-c63e-4f8b-86f6-d6ce80977827"
      },
      "source": [
        "# define the weight/transformation matrix as random numbers initially and hopefully it learns the correct weights during the training process\n",
        "\n",
        "caps2_n_caps = 10\n",
        "caps2_n_dims = 16\n",
        "\n",
        "caps1_n_caps = 1152\n",
        "caps1_n_dims = 8\n",
        "\n",
        "\n",
        "init_sigma = 0.1\n",
        "\n",
        "W_init = tf.random.normal(\n",
        "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
        "    stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
        "W = tf.Variable(W_init, name=\"W\")\n",
        "\n",
        "print(W_init.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1152, 10, 16, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6Dfn98XIFZT",
        "colab_type": "text"
      },
      "source": [
        "Since there are batch_size(=128) number of images that we are dealing with currently, need to replicate the values in the created weight matrix batch_size(=128) number of times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07tfGTuvDyB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\") # replicate only along the first dimension, hence kept others 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LjYAWp4EAvw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d42a7f26-f366-4b76-ebc9-38e0814666d3"
      },
      "source": [
        "print(W_tiled.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 1152, 10, 16, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_MGpmvIIkb8",
        "colab_type": "text"
      },
      "source": [
        "Looking at a single image: for each child capsule-parent capsule pair(total 1152*10 such pairs) we have (16, 8) transformation matrix.\n",
        "\n",
        "This is true for all the images in the batch, hence 128 is the first dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr6WvzBfEXgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(caps1_output.shape)\n",
        "\n",
        "caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
        "                                       name=\"caps1_output_expanded\")\n",
        "# print(caps1_output_expanded.shape)\n",
        "\n",
        "\n",
        "caps1_output_expanded2 = tf.expand_dims(caps1_output_expanded, 2,\n",
        "                                   name=\"caps1_output_tile\")\n",
        "# print(caps1_output_expanded2.shape)\n",
        "\n",
        "\n",
        "caps1_output_tiled = tf.tile(caps1_output_expanded2, [1, 1, caps2_n_caps, 1, 1],\n",
        "                             name=\"caps1_output_tiled\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqT3nmi0LiMf",
        "colab_type": "text"
      },
      "source": [
        "Earlier the shape of the primary capsule layer output was(128, 1152, 8).\n",
        "\n",
        "The above cell achieves the following:\n",
        "Earlier there were 1152 8-D vectors as the outputs of primary capsule layer, but since the output from 1 child capsule goes to all the capsules in the parent layer, the output of each child capsule needs to replicated as many times as there are capsules in the parent layer. This is done so that the same output is sent from a child capsule to each of the capsules in the parent layer.\n",
        "\n",
        "Hence now the outputs from the primary capsule layer are such that there is an output for every child-capsule, parent-capsule pair with all the outputs from one particular child capsule being the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJv4CDqqEuLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20216b7a-8dc9-4864-f5c5-79874afd7385"
      },
      "source": [
        "print(caps1_output_tiled.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 1152, 10, 8, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHHeuZtFNLVC",
        "colab_type": "text"
      },
      "source": [
        "Progress: We now have, for each child capsule-parent capsule pair an 8-D(8, 1) output vector which will be multiplied with a (16, 8) weight/transformation matrix to yield 16-D(16, 1) prediccted output vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIXigaokEyct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
        "                            name=\"caps2_predicted\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIHoEWtaFGBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d217949-c9e8-4ee5-ea19-ff964773a1cf"
      },
      "source": [
        "print(caps2_predicted.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 1152, 10, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKsP4P5TG-nA",
        "colab_type": "text"
      },
      "source": [
        "For each instance in the batch, and for each child capsule-parent capsule pair, i.e. 1152*10(number of capsules in child layer * number of capsules in parent layer)a vector, each of 16 dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOS4FJXbOSbt",
        "colab_type": "text"
      },
      "source": [
        "**Routing-by-agreement algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqyDW0qJG2EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}